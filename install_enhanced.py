import subprocess
import sys
import os
from huggingface_hub import snapshot_download
from sentence_transformers import SentenceTransformer
from config import EMBEDDING_MODEL_NAME, LANGCHAIN_CACHE_DIR

def install_spacy_model():
    """Install spaCy English model for advanced text processing"""
    try:
        print("ðŸ“¥ Installing spaCy English model...")
        subprocess.check_call([
            sys.executable, "-m", "spacy", "download", "en_core_web_sm"
        ])
        print("âœ… spaCy model installed successfully!")
        return True
    except Exception as e:
        print(f"âš ï¸ spaCy model installation failed: {str(e)}")
        return False

def download_nltk_data():
    """Download required NLTK data"""
    try:
        print("ðŸ“¥ Downloading NLTK data...")
        import nltk
        nltk.download('punkt')
        nltk.download('stopwords')
        nltk.download('wordnet')
        nltk.download('averaged_perceptron_tagger')
        print("âœ… NLTK data downloaded successfully!")
        return True
    except Exception as e:
        print(f"âš ï¸ NLTK data download failed: {str(e)}")
        return False

def download_embedding_model():
    """Download and verify embedding model"""
    try:
        print("ðŸ“¥ Downloading enhanced embedding model...")
        
        # Download via sentence-transformers (best method)
        model = SentenceTransformer(EMBEDDING_MODEL_NAME)
        
        # Test the model
        test_embedding = model.encode(["Enhanced LangChain RAG test"])
        print(f"âœ… Embedding model ready! Dimension: {len(test_embedding[0])}")
        
        # Cache model information
        os.makedirs(LANGCHAIN_CACHE_DIR, exist_ok=True)
        with open(os.path.join(LANGCHAIN_CACHE_DIR, "model_info.txt"), "w") as f:
            f.write(f"Model: {EMBEDDING_MODEL_NAME}\n")
            f.write(f"Dimension: {len(test_embedding[0])}\n")
            f.write(f"LangChain Enhanced: True\n")
        
        return True
        
    except Exception as e:
        print(f"âŒ Failed to download embedding model: {str(e)}")
        return False

def verify_langchain_installation():
    """Verify LangChain components are working"""
    try:
        print("ðŸ”§ Verifying LangChain installation...")
        
        # Test core imports
        from langchain.schema import Document
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain.vectorstores import FAISS
        from langchain.embeddings import SentenceTransformerEmbeddings
        
        # Test basic functionality
        splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)
        test_doc = Document(page_content="This is a test document for LangChain verification.")
        chunks = splitter.split_documents([test_doc])
        
        print(f"âœ… LangChain verification successful! Created {len(chunks)} test chunks")
        return True
        
    except Exception as e:
        print(f"âŒ LangChain verification failed: {str(e)}")
        return False

def main():
    """Enhanced model installation with LangChain setup"""
    print("ðŸš€ Enhanced LangChain RAG Setup")
    print("=" * 50)
    
    success_count = 0
    total_steps = 4
    
    # Step 1: Verify LangChain
    if verify_langchain_installation():
        success_count += 1
    
    # Step 2: Download embedding model
    if download_embedding_model():
        success_count += 1
    
    # Step 3: Install spaCy model (optional)
    if install_spacy_model():
        success_count += 1
    
    # Step 4: Download NLTK data (optional)
    if download_nltk_data():
        success_count += 1
    
    print(f"\nðŸ“Š Setup Results: {success_count}/{total_steps} components installed successfully")
    
    if success_count >= 2:  # Core components working
        print("\nðŸŽ‰ Enhanced LangChain RAG setup completed!")
        print("\nðŸŒŸ Your project now includes:")
        print("  âœ… Advanced LangChain text processing")
        print("  âœ… Multiple retrieval strategies")
        print("  âœ… Enhanced document analysis")
        print("  âœ… Intent-based query processing")
        print("  âœ… Contextual compression")
        print("  âœ… Conversation memory")
        print("\nðŸ“ Resume-worthy features:")
        print("  â€¢ Multi-strategy RAG implementation")
        print("  â€¢ LangChain vector store integration")
        print("  â€¢ Advanced document processing pipeline")
        print("  â€¢ Intent-based prompt engineering")
        print("  â€¢ Contextual compression and ranking")
        
        print("\nðŸš€ Run the application:")
        print("  streamlit run app.py")
    else:
        print("\nâš ï¸ Setup completed with some issues.")
        print("  The app should still work with basic functionality.")
    
    return success_count >= 2

if __name__ == "__main__":
    main()